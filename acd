#!/usr/bin/python

# rsync is supported with the --size-only flag:  rsync -avP --size-only /localfiles /acdfiles

from time import time
from stat import S_IFDIR, S_IFREG
from errno import *
import fuse
import pyacd
import os.path

fuse.fuse_python_api = (0, 2)

DEBUG = True

folder_types = ["ROOT", "FOLDER", "RECYCLE"]

class ACDFS(fuse.Fuse):
    api = None
    session = None
    email = None
    password = None

    infocache = {}
    dircache = {}
    filecache = {}

    def __init__(self, session=None, *args, **kw):
        fuse.Fuse.__init__(self, *args, **kw)
        self.api = pyacd.api
        if DEBUG: print 'Init complete.'

    def main(self):
        self.session = pyacd.login(self.email, self.password)
        fuse.Fuse.main(self)

    def getinfo(self, path):
        path = path.decode('utf_8')
        if path not in self.infocache:
            if DEBUG: print "*** CACHE MISS on path", path
            info = self.api.get_info_by_path(path)
            self.infocache[path] = info
        return self.infocache[path]

    def statfs(self):
        blocksize = 1
        storage = self.api.get_user_storage()
        total = storage.total_space
        free = storage.free_space

        myfs = fuse.StatVfs()
        myfs.f_bsize = blocksize
        myfs.f_frsize = blocksize
        myfs.f_blocks = total
        myfs.f_bfree = free
        myfs.f_bavail = free
        return myfs

    def getattr(self, path):
        path = path.decode('utf_8')
        if DEBUG: print 'called getattr:', path

        head, tail = os.path.split(path)
        nopaths = ['.git', 'objects']
        if tail in nopaths:
            return -ENOENT

        try:
            info = self.getinfo(path)
        except pyacd.PyAmazonCloudDriveError as e:
            print e
            return -ENOENT

        st = fuse.Stat()
        st.st_atime = int(time())
        st.st_mtime = info.modified
        st.st_ctime = info.created

        if info.Type in folder_types:
            st.st_mode = S_IFDIR | 0755
            st.st_nlink = 2
            return st
        elif info.Type == "FILE":
            st.st_mode = S_IFREG | 0644
            st.st_nlink = 1
            st.st_size = info.size and info.size or 0
            return st
        else: return -ENOENT

    def readdir(self, path, offset):
        path = path.decode('utf_8')
        if DEBUG: print 'readdir called:', path

        yield fuse.Direntry('.')
        yield fuse.Direntry('..')

        if path in self.dircache:
            for x in self.dircache[path]:
                yield fuse.Direntry(x)
        else:
            info = self.getinfo(path)
            if info.Type not in folder_types:
                if DEBUG: print path, " is not a folder!"
                raise StopIteration

            folder = self.api.list_by_id(info.object_id)
            names = [x.name.encode('utf8', 'replace') for x in folder.objects]
            self.dircache[path] = names

            for x in names:
                yield fuse.Direntry(x)

    def read(self, path, size, offset):
        path = path.decode('utf_8')
        if DEBUG: print 'read called:', path

        data = None
        if path not in self.filecache:
            info = self.getinfo(path)
            self.filecache[path] = self.api.download_by_id(info.object_id)

        data = self.filecache[path]
        file_size = len(data)
        if offset < file_size:
            if offset + size > file_size:
                size = file_size - offset
            return data[offset:offset+size]
        else:
            #filecache.pop(path)
            return ''

    def unlink(self, path):
        path = path.decode('utf_8')
        if DEBUG: print 'unlink called:', path

        info = self.getinfo(path)
        self.api.remove_bulk_by_id([info.object_id])
        head, tail = os.path.split(path)
        if path in self.infocache:
            self.infocache.pop(path)
        if head in self.dircache:
            self.dircache.pop(head)

    def rmdir(self, path):
        path = path.decode('utf_8')
        if DEBUG: print 'rmdir called:', path
        self.unlink(path)

    def mkdir(self, path, mode):
        path = path.decode('utf_8')
        if DEBUG: print 'mkdir called:', path

        head, tail = os.path.split(path)
        newdir = self.api.create_by_path(head, tail, Type=pyacd.types.FOLDER)
        if path in self.infocache:
            self.infocache.pop(path)
        if head in self.dircache:
            self.dircache.pop(head)

    def rename(self, path1, path2):
        path1 = path1.decode('utf_8')
        path2 = path2.decode('utf_8')
        if DEBUG: print 'rename called: %s -> %s' % (path1, path2)

        head, tail = os.path.split(path2)

        info1 = self.getinfo(path1)
        dirinfo = self.getinfo(head)
        result = self.api.move_by_id(info1.object_id, dirinfo.object_id, tail)

        if path1 in self.infocache:
            self.infocache.pop(path1)
        if head in self.dircache:
            self.dircache.pop(head)

    def chmod(self, path, mode):
        return 0
    def chown(self, path, uid, gid):
        return 0
    def utime(self, path, times):
        return 0

    def create(self, path, flags, mode):
        path = path.decode('utf_8')
        if DEBUG: print 'create called:', path

        head, tail = os.path.split(path)
        self.infocache[path] = self.api.create_by_path(head, tail)

    def write(self, path, buf, offset):
        path = path.decode('utf_8')
        if DEBUG: print "write \"%s\" %u bytes, to offset %u" % (path, len(buf), offset)

        if path not in self.filecache:
            self.filecache[path] = buf
        else:
            self.filecache[path] += buf
        return len(buf)

    def flush(self, path):
        pass

    def release(self, path, flags):
        basename = os.path.basename(path)
        dirname = os.path.dirname(path)
        newfile = self.infocache[path]
        buf = self.filecache[path]
        url = self.api.get_upload_url_by_id(newfile.object_id, len(buf))
        result = self.api.upload(url.http_request.end_point, url.http_request.parameters, basename, buf)
        result = self.api.complete_file_upload_by_id(url.object_id, url.storage_key)

        if dirname in self.dircache:
            self.dircache.pop(dirname)
        if path in self.infocache:
            self.infocache.pop(path)
        self.filecache.pop(path)
        return len(buf)


if __name__ == '__main__':
    fs = ACDFS()
    fs.flags = 0
    fs.multithreaded = 0

    fs.parser.add_option(mountopt="email", metavar="EMAIL",
                         help="EMAIL login for Amazon Cloud Drive")
    fs.parser.add_option(mountopt="password", metavar="PASSWORD",
                         help="PASSWORD password for Amazon Cloud Drive")

    fs.parse(values=fs, errex=1)
    fs.main()
